import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import json
import locale
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
from dateutil.relativedelta import relativedelta
import warnings
import requests # A√±adido para futuras integraciones

warnings.filterwarnings('ignore')
try:
    # Para el servidor (Linux) - esto funcionar√° gracias a packages.txt
    locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')
except locale.Error:
    try:
        # Fallback para tu m√°quina local (Windows)
        locale.setlocale(locale.LC_TIME, 'Spanish')
    except locale.Error:
        # √öltimo recurso, usar el default del sistema
        locale.setlocale(locale.LC_TIME, '')
        print("Advertencia: No se pudo configurar el locale 'es_ES.UTF-8' ni 'Spanish'. Usando el default.")
# =============================================================================
# CONFIGURACI√ìN DE P√ÅGINA
# =============================================================================
st.set_page_config(
    page_title="Dashboard PlusSteel",
    # MODIFICADO: Estandarizado al logo circular rojo
    page_icon="assets/logo2.png",  
    layout="wide",
    initial_sidebar_state="expanded"
)
# CSS Personalizado (basado en tu c√≥digo)
st.markdown("""
<style>
body {
    font-family: 'Segoe UI', sans-serif;
}
h1, h2, h3, h4 {
    color: #E0E0E0;
}
div.stButton > button {
    background-color: #E0E0E0;
    color: #212121;
    font-weight: bold;
    border: none;
    border-radius: 8px;
    padding: 0.5em 1.5em;
}
div.stButton > button:hover {
    background-color: #B0B0B0;
    color: #000000;
}
[data-testid="stMetricDelta"] {
    color: #FFCC00;
}
/* Inputs (Base) */
input, select, textarea {
    border-radius: 8px !important;
    background-color: #2C2C2C;
    color: #FFFFFF;
    border: 1px solid #444;
}

section[data-testid="stSidebar"] {
    background-color: #CC0000 !important;
    color: #FFFFFF;
}
hr {
    border: 0;
    height: 1px;
    background: #444;
    margin: 2em 0;
}
</style>
""", unsafe_allow_html=True)
# =============================================================================
# CONSTANTES Y RUTAS
# =============================================================================
BASE_EXPORT_DIR = 'models_export'
DATA_FILE = '08_series_temporales_clase_a_con_kmeans.xlsx'
DIR_BASE_MODELOS = os.path.join(BASE_EXPORT_DIR, 'doble_clasificador')
DIR_REENTRENADOS = os.path.join(BASE_EXPORT_DIR, 'reentrenamiento_doble_clasif')
DIR_UMBRALES = os.path.join(BASE_EXPORT_DIR, 'optimizacion_umbral')
PLANIFICACION_FILE = 'planificacion_demanda.csv'

# Archivos de modelos para monitorear fechas
MODELOS_BASE_FILE = os.path.join(DIR_BASE_MODELOS, 'modelos_doble_clasif.pkl')
MODELOS_REENTRENADOS_FILE = os.path.join(DIR_REENTRENADOS, 'modelos_reentrenados.pkl')


# =============================================================================
# FUNCIONES AUXILIARES (DE TU NOTEBOOK)
# =============================================================================
def preparar_datos_doble_clasificador(df_segmento):
    """
    Prepara datos para modelo doble-clasificador (desde Celda 10.5)
    """
    from sklearn.preprocessing import StandardScaler
    from numpy import log1p
    
    df_prep = df_segmento.copy()
    df_prep['fecha'] = pd.to_datetime(df_prep['fecha'])
    df_prep['venta_ocurrio'] = (df_prep['cantidad_vendida'] > 0).astype(int)
    
    ventas_positivas = df_prep[df_prep['venta_ocurrio'] == 1]['cantidad_vendida']
    limites_rangos = None
    df_prep['rango_venta'] = -1
    
    if len(ventas_positivas) > 10:
        q_50 = ventas_positivas.quantile(0.50)
        limites_rangos = {'q_50': float(q_50)}
        indices_venta = df_prep[df_prep['venta_ocurrio'] == 1].index
        df_prep.loc[indices_venta, 'rango_venta'] = pd.cut(
            ventas_positivas,
            bins=[-np.inf, q_50, np.inf],
            labels=[0, 1],
            right=False
        ).astype(int)
    
    features_list = []
    for producto in df_prep['producto'].unique():
        df_prod = df_prep[df_prep['producto'] == producto].sort_values('fecha').copy()
        
        cantidad_segura = df_prod['cantidad_vendida'].replace(0, np.nan)
        df_prod['precio_implicito'] = df_prod['venta_bs'] / cantidad_segura
        df_prod['precio_implicito'] = df_prod['precio_implicito'].ffill().bfill().fillna(0)
        
        precio_medio_hist = df_prod['precio_implicito'][df_prod['precio_implicito'] > 0].mean()
        if precio_medio_hist > 0:
            df_prod['precio_relativo'] = (df_prod['precio_implicito'] / precio_medio_hist) - 1.0
        else:
            df_prod['precio_relativo'] = 0.0
        
        df_prod['hubo_descuento_implicito'] = (df_prod['precio_relativo'] < -0.05).astype(int)
        df_prod['fecha_ultima_compra'] = df_prod['fecha'].where(df_prod['venta_ocurrio'] == 1).ffill()
        
        if 'fecha_ultima_compra' in df_prod.columns and not df_prod['fecha_ultima_compra'].isna().all():
            df_prod['dias_desde_ultima_compra'] = (df_prod['fecha'] - df_prod['fecha_ultima_compra']).dt.days
            df_prod['dias_desde_ultima_compra'] = df_prod['dias_desde_ultima_compra'].fillna(0).astype(int)
        else:
            df_prod['dias_desde_ultima_compra'] = 0
        
        racha_no_venta = (df_prod['venta_ocurrio'] != 0).cumsum()
        df_prod['racha_de_no_venta'] = df_prod.groupby(racha_no_venta).cumcount()
        
        df_prod['mes'] = df_prod['fecha'].dt.month
        df_prod['trimestre'] = df_prod['fecha'].dt.quarter
        df_prod['mes_sin'] = np.sin(2 * np.pi * df_prod['mes'] / 12)
        df_prod['mes_cos'] = np.cos(2 * np.pi * df_prod['mes'] / 12)
        
        for lag in [1, 3, 6]:
            df_prod[f'lag_{lag}'] = df_prod['cantidad_vendida'].shift(lag)
            df_prod[f'venta_ocurrio_lag_{lag}'] = df_prod['venta_ocurrio'].shift(lag)
        
        for ventana in [3, 6]:
            df_prod[f'media_movil_{ventana}'] = (
                df_prod['cantidad_vendida'].shift(1)
                .rolling(window=ventana, min_periods=1).mean()
            )
        
        for ventana in [3, 6, 12]:
            df_prod[f'tasa_ocurrencia_{ventana}'] = (
                df_prod['venta_ocurrio'].shift(1)
                .rolling(window=ventana, min_periods=1).mean()
            )
        
        features_list.append(df_prod)
    
    if not features_list:
        return pd.DataFrame(), [], None
    
    df_features = pd.concat(features_list, ignore_index=True)
    feature_cols = [col for col in df_features.columns if col not in
                        ['producto', 'fecha', 'cantidad_vendida', 'venta_bs',
                        'num_transacciones', 'periodo', 'venta_ocurrio',
                        'subclase_kmeans', 'grupo_venta', 'rango_venta',
                        'fecha_ultima_compra', 'precio_implicito']]
    
    df_features = df_features.replace([np.inf, -np.inf], np.nan).fillna(0)
    return df_features, feature_cols, limites_rangos

def predecir_producto(df_single_row, segmento, modelos, scalers, features, limites, umbrales):
    """
    Predice probabilidades para una fila (desde Celda 12)
    """
    try:
        modelo_dict = modelos[segmento]
        scaler = scalers[segmento]
        feature_cols = features[segmento]
        umbral = umbrales.get(segmento, 0.5)
        limite = limites[segmento]
    except KeyError as e:
        return None
    
    X_pred = df_single_row.reindex(columns=feature_cols).fillna(0)
    X_scaled = scaler.transform(X_pred)
    
    cls_binario = modelo_dict.get('clasificador_binario')
    cls_rangos = modelo_dict.get('clasificador_rangos')
    
    if cls_rangos is None:
        return None
    
    if cls_binario is None:
        prob_venta = 1.0
    else:
        prob_venta = cls_binario.predict_proba(X_scaled)[0, 1]
    
    prob_rangos = cls_rangos.predict_proba(X_scaled)[0]
    prob_no_venta = 1.0 - prob_venta
    prob_venta_baja = prob_venta * prob_rangos[0]
    prob_venta_alta = prob_venta * prob_rangos[1]
    
    return {
        'segmento': segmento,
        'limite_baja_alta': limite.get('q_50', 0), 
        'P(No Venta)': prob_no_venta,
        'P(Venta Baja)': prob_venta_baja,
        'P(Venta Alta)': prob_venta_alta,
        'prob_total_venta': prob_venta,
        'umbral_optimizado_usado': umbral 
    }

def obtener_precio_promedio(df_historial_producto):
    """
    Calcula el precio promedio ponderado de un producto.
    """
    df_ventas_reales = df_historial_producto[df_historial_producto['cantidad_vendida'] > 0]
    
    if df_ventas_reales.empty:
        return 0 

    venta_total_bs = df_ventas_reales['venta_bs'].sum()
    cantidad_total = df_ventas_reales['cantidad_vendida'].sum()
    
    if cantidad_total == 0:
        return 0
        
    return venta_total_bs / cantidad_total

# =============================================================================
# CARGA DE DATOS (CACHEADA Y EN SESSION STATE)
# =============================================================================

@st.cache_data
def cargar_artefactos():
    """
    Carga modelos, scalers, datos hist√≥ricos y recomendaciones
    """
    try:
        # Modelos base
        modelos_base = joblib.load(MODELOS_BASE_FILE)
        scalers_prod = joblib.load(os.path.join(DIR_BASE_MODELOS, 'scalers_doble_clasif.pkl'))
        features_prod = joblib.load(os.path.join(DIR_BASE_MODELOS, 'features_doble_clasif.pkl'))
        limites_prod = joblib.load(os.path.join(DIR_BASE_MODELOS, 'limites_rangos.pkl'))
        
        # Umbrales
        try:
            with open(os.path.join(DIR_UMBRALES, 'umbrales_optimizados.json'), 'r') as f:
                umbrales_prod = json.load(f)
        except FileNotFoundError:
            umbrales_prod = {}
        
        # Modelos reentrenados
        try:
            modelos_reentrenados = joblib.load(MODELOS_REENTRENADOS_FILE)
            scalers_reentrenados = joblib.load(os.path.join(DIR_REENTRENADOS, 'scalers_reentrenados.pkl'))
        except FileNotFoundError:
            modelos_reentrenados = {}
            scalers_reentrenados = {}
        
        # Consolidar
        modelos_prod = modelos_base.copy()
        scalers_final = scalers_prod.copy()
        for seg, modelo in modelos_reentrenados.items():
            if seg in modelos_prod:
                modelos_prod[seg] = modelo
                scalers_final[seg] = scalers_reentrenados[seg]
        
        # Datos hist√≥ricos
        df_series = pd.read_excel(DATA_FILE)
        
        # Recomendaciones (AHORA PLANIFICACION)
        try:
            df_planif = pd.read_csv(PLANIFICACION_FILE)
        except FileNotFoundError:
            df_planif = None
        
        return True, modelos_prod, scalers_final, features_prod, limites_prod, umbrales_prod, df_series, df_planif
    
    except Exception as e:
        st.error(f"Error cargando artefactos: {e}")
        return False, None, None, None, None, None, None, None

# L√≥gica de carga con st.session_state
if 'datos_cargados' not in st.session_state:
    with st.spinner("Cargando modelos y datos..."):
        (
            success,
            st.session_state['modelos_prod'],
            st.session_state['scalers_prod'],
            st.session_state['features_prod'],
            st.session_state['limites_prod'],
            st.session_state['umbrales_prod'],
            st.session_state['df_series'],
            st.session_state['df_planif']
        ) = cargar_artefactos()
        st.session_state['datos_cargados'] = success

if not st.session_state['datos_cargados']:
    st.error("No se pudieron cargar los artefactos. Verifica que existan los archivos de modelo.")
    st.stop()
else:
    # MODIFICADO: Emoji eliminado
    st.toast("Modelos y datos cargados.")


# =============================================================================
# SIDEBAR - NAVEGACI√ìN Y DATOS
# =============================================================================
with st.sidebar:
    # MODIFICADO: Estandarizado al logo circular rojo
    st.image("assets/logo1.png", use_container_width=True) 
    
    # MODIFICADO: Men√∫ de navegaci√≥n sin emojis
    st.markdown("## Men√∫ Principal")
    pagina_seleccionada = st.radio(
        "Seleccione una p√°gina:",
        [
            "Inicio", 
            "Pron√≥stico", 
            "Planificaci√≥n de Demanda", 
            "Segmentaci√≥n K-Means", 
            "Salud del Modelo (MLOps)"
        ],
        label_visibility="collapsed"
    )
    
    st.markdown("---")
    st.markdown("### Informaci√≥n del Sistema")
    
    # Acceder a los datos desde session_state
    df_series = st.session_state['df_series']
    modelos_prod = st.session_state['modelos_prod']
    
    st.markdown(f"""
    - **Productos Clase A:** {len(df_series['producto'].unique())}
    - **Segmentos K-Means:** {df_series['subclase_kmeans'].nunique()}
    - **Modelos Cargados:** {len(modelos_prod)}
    - **Rango de Datos:** {pd.to_datetime(df_series['fecha']).min().strftime('%Y-%m')} - {pd.to_datetime(df_series['fecha']).max().strftime('%Y-%m')}
    """)
    
    # Fecha de actualizaci√≥n de modelos
    try:
        if os.path.exists(MODELOS_REENTRENADOS_FILE):
            fecha_mod = os.path.getmtime(MODELOS_REENTRENADOS_FILE)
        else:
            fecha_mod = os.path.getmtime(MODELOS_BASE_FILE)
        fecha_str = datetime.fromtimestamp(fecha_mod).strftime('%Y-%m-%d %H:%M')
        st.info(f"√öltima act. de modelos:\n**{fecha_str}**")
    except Exception as e:
        st.warning(f"No se pudo leer la fecha del modelo.")
    
    st.markdown("---")
    st.markdown("### Tecnolog√≠as Usadas")
    st.markdown("""
    - Streamlit
    - Scikit-learn
    - Random Forest
    - K-Means Clustering
    - Plotly
    """)


# =============================================================================
# INTERFAZ PRINCIPAL - CONTENIDO CONDICIONAL
# =============================================================================

# =============================================================================
# P√ÅGINA 1: INICIO (NUEVA)
# =============================================================================
if pagina_seleccionada == "Inicio":
    
    st.title("Bienvenido al Dashboard de PlusSteel")
    st.markdown("Sistema de Pron√≥stico de Demanda con Inteligencia Artificial")
    
    st.subheader("Qui√©nes Somos")
    st.markdown("""
    Somos una empresa que naci√≥ con el firme compromiso de ser l√≠deres en la fabricaci√≥n de perfiler√≠a met√°lica
    y sistemas para la construcci√≥n en seco **DRY WALL** y **STEEL FRAME**¬Æ. 
    
    Nuestra certificaci√≥n **ISO 9001** v√°lida nuestro compromiso con la excelencia y la satisfacci√≥n del cliente.
    """)
    
    st.markdown("---")

    st.subheader("Nuestros Valores")
    col1, col2, col3 = st.columns(3)
    with col1:
        # MODIFICADO: Emoji eliminado
        st.markdown("#### Calidad ISO 9001")
        st.markdown("Somos la Primera F√°brica Boliviana en la fabricaci√≥n de perfiles de acero galvanizado para construcci√≥n en seco con certificaci√≥n ISO 9001.")
    with col2:
        # MODIFICADO: Emoji eliminado
        st.markdown("#### Experiencia")
        st.markdown("Vasta experiencia en cerchas met√°licas, cielos falsos, muros divisorios y fachadas en proyectos p√∫blicos y privados.")
    with col3:
        # MODIFICADO: Emoji eliminado
        st.markdown("#### Asesoramiento Profesional")
        st.markdown("Profundo conocimiento de nuestros productos y servicios para ayudarte a tomar decisiones informadas que impulsen el √©xito de tu proyecto.")

    st.markdown("---")

    st.subheader("Categor√≠as Principales de Productos")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        - **Perfiler√≠a:** Perfiles estructurales STEEL FRAME y perfiles livianos DRY WALL.
        - **Construcci√≥n:** Aislamientos t√©rmicos/ac√∫sticos, Cercha met√°lica, Cielo falso.
        - **Complementos:** Variedad en cintas, mallas y tornillos.
        - **Placas:** Amplia gama en placas cementicias, de yeso y desmontables.
        """)
    with col2:
        st.markdown("""
        - **Paneles para Fachadas:** Paneles de Aluminio Compuesto, Hunter Douglas y Lamitech.
        - **Revestimiento Interiores:** Hunter Douglas Interior y Pertech by Lamitech.
        - **Herramientas**
        - **Protecci√≥n Personal**
        """)

# =============================================================================
# P√ÅGINA 2: PRON√ìSTICO (Antes Tab 1)
# =============================================================================
elif pagina_seleccionada == "Pron√≥stico":

    st.header("Pron√≥stico de Demanda por Producto")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        lista_productos = sorted(st.session_state['df_series']['producto'].unique())
        producto_sel = st.selectbox(
            "Seleccione un producto Clase A:",
            lista_productos,
            key="producto_pronostico"
        )
    
    with col2:
        st.metric("Total de productos Clase A", len(lista_productos))
    
    # MODIFICADO: Emoji eliminado
    if st.button("Generar Pron√≥stico", type="primary"):
        with st.spinner(f"Generando pron√≥stico para '{producto_sel}'..."):
            try:
                df_historial = st.session_state['df_series'][st.session_state['df_series']['producto'] == producto_sel].copy()
                df_historial['fecha'] = pd.to_datetime(df_historial['fecha'])
                segmento = df_historial['subclase_kmeans'].iloc[0]
                
                # Validar modelo
                if segmento not in st.session_state['modelos_prod']:
                    # MODIFICADO: Emoji eliminado
                    st.error(f"No existe modelo entrenado para el segmento '{segmento}'")
                    st.stop()
                
                # Preparar predicci√≥n
                fecha_ultima = df_historial['fecha'].max()
                fecha_pred = (fecha_ultima + relativedelta(months=1)).replace(day=1)
                
                df_futuro = pd.DataFrame([{
                    'producto': producto_sel,
                    'fecha': fecha_pred,
                    'cantidad_vendida': 0,
                    'venta_bs': 0,
                    'num_transacciones': 0,
                    'subclase_kmeans': segmento
                }])
                
                df_combined = pd.concat([df_historial, df_futuro], ignore_index=True)
                df_features, feature_cols, _ = preparar_datos_doble_clasificador(df_combined)
                
                if df_features.empty:
                    st.error("No se pudieron generar features para el pron√≥stico.")
                    st.stop()

                df_pred = df_features.iloc[[-1]]
                
                resultado = predecir_producto(
                    df_pred, segmento, 
                    st.session_state['modelos_prod'], 
                    st.session_state['scalers_prod'],
                    st.session_state['features_prod'], 
                    st.session_state['limites_prod'], 
                    st.session_state['umbrales_prod']
                )
                
                if resultado:
                    # Mostrar resultados
                    st.subheader(f"Pron√≥stico para {fecha_pred.strftime('%B %Y')}")
                    st.info(f"Producto: **{producto_sel}** | Segmento: **{segmento}**")
                    
                    limite = resultado['limite_baja_alta']
                    
                    # MODIFICADO: Emojis eliminados de recomendaciones
                    if resultado['P(No Venta)'] > 0.6:
                        st.warning(f"**Recomendaci√≥n: Stock M√≠nimo.**\n\nAlta probabilidad ({resultado['P(No Venta)']:.1%}) de no vender.")
                    elif resultado['P(Venta Alta)'] > resultado['P(Venta Baja)'] and resultado['P(Venta Alta)'] > 0.35:
                        st.success(f"**Recomendaci√≥n: Priorizar Reabastecimiento.**\n\nAlta demanda esperada (Prob. Venta Alta: {resultado['P(Venta Alta)']:.1%}).")
                    else:
                        st.info(f"**Recomendaci√≥n: Demanda Moderada.**\n\nReabastecer con cautela (Prob. Venta Baja: {resultado['P(Venta Baja)']:.1%}).")

                    
                    # ==========================================================
                    # ‚≠ê INICIO DE BLOQUE MODIFICADO (PASO 2)
                    # ==========================================================
                    
                    # 1. Obtener datos del mes pasado (el √∫ltimo registro del historial)
                    df_historial.sort_values('fecha', ascending=True, inplace=True)
                    last_month_data = df_historial.iloc[-1]
                    last_month_qty = last_month_data['cantidad_vendida']
                    last_month_bs = last_month_data['venta_bs']
                    last_month_date_str = last_month_data['fecha'].strftime('%B %Y')

                    # 2. Obtener precio promedio (usando la funci√≥n que ya existe)
                    precio_promedio = obtener_precio_promedio(df_historial)

                    # 3. Definir cantidades esperadas (usando heur√≠stica de Celda 13)
                    cantidad_esperada_baja = limite * 0.5
                    cantidad_esperada_alta = limite * 1.5

                    # 4. Calcular el Valor Esperado (Bs.)
                    valor_esperado_baja = resultado['P(Venta Baja)'] * cantidad_esperada_baja * precio_promedio
                    valor_esperado_alta = resultado['P(Venta Alta)'] * cantidad_esperada_alta * precio_promedio
                    valor_total_esperado = valor_esperado_baja + valor_esperado_alta
                    
                    # 5. Calcular Demanda Esperada (en Cantidad) para el delta
                    demanda_qty_esperada = (resultado['P(Venta Baja)'] * cantidad_esperada_baja) + (resultado['P(Venta Alta)'] * cantidad_esperada_alta)
                    delta_qty_str = f"{demanda_qty_esperada - last_month_qty:,.1f} u. vs mes anterior"


                    # 6. Mostrar m√©tricas en columnas para comparar
                    col_met1, col_met2 = st.columns(2)
                    
                    with col_met1:
                        st.metric(
                            label=f"Venta Mes Anterior ({last_month_date_str})",
                            value=f"{last_month_qty:,.0f} u.",
                            help=f"Valor en Bs.: {last_month_bs:,.2f}"
                        )
                    
                    with col_met2:
                        st.metric(
                            label=f"Pron√≥stico de Demanda ({fecha_pred.strftime('%B %Y')})",
                            value=f"{demanda_qty_esperada:,.1f} u.",
                            delta=delta_qty_str
                        )

                    # Mostrar la m√©trica de Bs. debajo
                    st.metric(
                        label=f"Valor Total Esperado ({fecha_pred.strftime('%B %Y')})",
                        value=f"Bs. {valor_total_esperado:,.2f}",
                        help=f"Estimaci√≥n basada en un precio promedio de Bs. {precio_promedio:,.2f}/u. "
                             f"Valor Esperado (Baja): Bs. {valor_esperado_baja:,.2f}. "
                             f"Valor Esperado (Alta): Bs. {valor_esperado_alta:,.2f}."
                    )
                    
                    # ==========================================================
                    # ‚≠ê FIN DE BLOQUE MODIFICADO
                    # ==========================================================


                    st.markdown("---")
                    
                    # Gr√°fico de Donut para probabilidades
                    col_chart, col_hist = st.columns([1, 2])
                    
                    with col_chart:
                        st.markdown(f"**Probabilidades (L√≠mite: {limite:.0f}u)**")
                        
                        labels = [f"No Venta", f"Venta Baja (<{limite:.0f}u)", f"Venta Alta (>{limite:.0f}u)"]
                        values = [resultado['P(No Venta)'], resultado['P(Venta Baja)'], resultado['P(Venta Alta)']]
                        
                        # Colores (Rojo acento, Amarillo advertencia, Gris neutral)
                        colors = ['#FFC107', '#B0B0B0', '#CC0000']

                        fig_pie = go.Figure(data=[go.Pie(
                            labels=labels, 
                            values=values, 
                            hole=.5,
                            marker=dict(colors=colors, line=dict(color='#FFFFFF', width=1)),
                            textinfo='percent+label',
                            textfont_size=14,
                            textfont_color="#FFFFFF"
                        )])
                        fig_pie.update_layout(
                            title_text="Distribuci√≥n de Probabilidad",
                            title_x=0.5,
                            height=400,
                            showlegend=False,
                            margin=dict(t=50, b=0, l=0, r=0),
                            paper_bgcolor='rgba(0,0,0,0)', 
                            plot_bgcolor='rgba(0,0,0,0)',
                            font_color="#FFFFFF"
                        )
                        st.plotly_chart(fig_pie, use_container_width=True)

                    with col_hist:
                        # Gr√°fico hist√≥rico
                        st.markdown("**Historial de Ventas**")
                        fig = go.Figure()
                        fig.add_trace(go.Scatter(
                            x=df_historial['fecha'],
                            y=df_historial['cantidad_vendida'],
                            mode='lines+markers',
                            name='Hist√≥rico',
                            # El gr√°fico usar√° el primaryColor (Plata) por defecto
                            line=dict(width=2) 
                        ))
                        
                        fig.add_vline(
                            x=fecha_pred.timestamp() * 1000, 
                            line_width=2, 
                            line_dash="dash", 
                            line_color="white", # L√≠nea blanca
                            annotation_text="Pron√≥stico",
                            annotation_position="top left"
                        )
                        
                        fig.update_layout(
                            title=f"Serie Temporal: {producto_sel}",
                            xaxis_title="Fecha",
                            yaxis_title="Cantidad Vendida",
                            hovermode='x unified',
                            height=400,
                            margin=dict(t=50, b=0, l=0, r=0),
                            paper_bgcolor='rgba(0,0,0,0)',
                            plot_bgcolor='rgba(0,0,0,0)',
                            font_color="#FFFFFF"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # MODIFICADO: Emoji eliminado
                    with st.expander("Ver JSON Detallado del Pron√≥stico"):
                        st.json(resultado)
                
            except Exception as e:
                st.error(f"Error: {e}")
                import traceback
                st.code(traceback.format_exc())

# =============================================================================
# P√ÅGINA 3: PLANIFICACI√ìN (Antes Tab 2)
# =============================================================================
elif pagina_seleccionada == "Planificaci√≥n de Demanda":

    # ==========================================================
    # ‚≠ê INICIO DE BLOQUE MODIFICADO (NUEVAS FUNCIONES Y COLORES)
    # ==========================================================
    
    # Funci√≥n para colorear la tabla (Tema Oscuro)
    # MODIFICADO: para que coincida con los datos reales de tu CSV
    def color_accion(accion):
        accion_str = str(accion).upper() # Convertir a may√∫sculas para seguridad
        if "URGENTE" in accion_str:
            color = 'color: #FF8A8A; font-weight: bold;' # Rojo claro
        elif "COMPRAR" == accion_str: # Coincidencia exacta
            color = 'color: #A5D6A7;' # Verde claro
        elif "NO COMPRAR" in accion_str:
            color = 'color: #B0B0B0;' # Gris
        else:
            color = 'color: #FFFFFF' # Blanco por defecto
        return color
    
    st.header("Planificaci√≥n de Demanda y Stock de Seguridad")
    
    # --- BLOQUE DE NOTIFICACI√ìN ELIMINADO ---
    
    st.markdown("---")
    
    df_planif = st.session_state['df_planif']
    
    if df_planif is not None:
        st.markdown(f"**Total de productos Clase A:** {len(df_planif)}")
        
        # Filtros
        col1, col2 = st.columns(2)
        with col1:
            filtro_accion = st.multiselect(
                "Filtrar por Acci√≥n:",
                options=df_planif['accion_recomendada'].unique() if 'accion_recomendada' in df_planif.columns else [],
                default=None
            )
        with col2:
            filtro_segmento = st.multiselect(
                "Filtrar por Segmento:",
                options=df_planif['segmento'].unique() if 'segmento' in df_planif.columns else [],
                default=None
            )
        
        # Aplicar filtros
        df_filtrado = df_planif.copy()
        if filtro_accion:
            df_filtrado = df_filtrado[df_filtrado['accion_recomendada'].isin(filtro_accion)]
        if filtro_segmento:
            df_filtrado = df_filtrado[df_filtrado['segmento'].isin(filtro_segmento)]
        
        # Columnas a mostrar
        columnas_visibles = [
            'producto', 
            'segmento', 
            'accion_recomendada', 
            'stock_seguridad_sugerido',
            'demanda_esperada',
            'punto_reorden',
            'prob_venta_alta',
            'prob_no_venta',
            'venta_promedio_6m'
        ]
        
        # ==========================================================
        # ‚≠ê INICIO DE BLOQUE MODIFICADO (RENOMBRADO DE TABLA)
        # ==========================================================
        
        # Mapeo de nombres de columnas
        column_rename_map = {
            'producto': 'Producto',
            'segmento': 'Segmento',
            'accion_recomendada': 'Acci√≥n Recomendada',
            'stock_seguridad_sugerido': 'Stock Seguridad (u.)',
            'demanda_esperada': 'Demanda Estimada (u.)',
            'punto_reorden': 'Punto de Reorden (u.)',
            'prob_venta_alta': 'Prob. Venta Alta',
            'prob_no_venta': 'Prob. No Venta',
            'venta_promedio_6m': 'Venta Prom. 6M (u.)'
        }
        # Aplicar el renombrado solo a las columnas visibles
        df_display = df_filtrado[columnas_visibles].rename(columns=column_rename_map)
        
        # Aplicar estilo de color a la tabla
        st.dataframe(
            df_display.style  # <--- Usar df_display
            .set_properties(**{'color': '#FFFFFF'})  # Texto blanco
            .set_table_styles([{'selector': 'thead th', 'props': [('color', '#E0E0E0')]}])
            .applymap(
                color_accion, subset=['Acci√≥n Recomendada'] # <--- Usar nuevo nombre
            ).format({
                'Stock Seguridad (u.)': '{:.1f} u.', # <--- Usar nuevos nombres y formatos
                'Demanda Estimada (u.)': '{:.1f} u.',
                'Punto de Reorden (u.)': '{:.1f} u.',
                'Prob. Venta Alta': '{:.1%}',
                'Prob. No Venta': '{:.1%}',
                'Venta Prom. 6M (u.)': '{:.1f} u.'
            }),
            use_container_width=True,
            height=500
        )
        # ==========================================================
        # ‚≠ê FIN DE BLOQUE MODIFICADO
        # ==========================================================
        
        # Resumen
        st.subheader("Resumen de Acciones")
        if 'accion_recomendada' in df_filtrado.columns:
            resumen = df_filtrado['accion_recomendada'].value_counts()
            
            # MODIFICADO: Colores del pie chart para coincidir con tu screenshot
            color_map = {
                "COMPRAR URGENTE": "#CC0000",            # Rojo
                "COMPRAR": "#A5D6A7",                  # Verde
                "NO COMPRAR": "#B0B0B0",                 # Gris
                # A√±adidos por si acaso
                "MANTENER": "#B0B0B0",                 
                "COMPRAR CON CAUTELA": "#FFC107",
                "NO COMPRAR - Liquidar stock": "#B0B0B0"
            }
            nombres_resumen = resumen.index.tolist()
            colores_mapeados = [color_map.get(str(nombre), '#B0B0B0') for nombre in nombres_resumen]

            fig = px.pie(
                values=resumen.values,
                names=nombres_resumen,
                title="Distribuci√≥n de Acciones Recomendadas",
            )
            fig.update_traces(
                marker=dict(colors=colores_mapeados, line=dict(color='#FFFFFF', width=1)),
                textfont_color="#000000"
            )
            fig.update_layout(
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)',
                font_color="#FFFFFF"
            )
            st.plotly_chart(fig, use_container_width=True)
    else:
        # MODIFICADO: Emoji eliminado
        st.warning(f"No se encontr√≥ el archivo '{PLANIFICACION_FILE}'.")
        st.info("Ejecuta la **Celda 13** del notebook para generar el reporte de planificaci√≥n.")

# =============================================================================
# P√ÅGINA 4: SEGMENTACI√ìN (Antes Tab 3)
# =============================================================================
elif pagina_seleccionada == "Segmentaci√≥n K-Means":

    st.header("Visualizaci√≥n de Segmentaci√≥n K-Means")
    
    # Preparar datos para scatter plot
    df_agregado = st.session_state['df_series'].groupby(['producto', 'subclase_kmeans']).agg({
        'cantidad_vendida': 'sum',
        'venta_bs': 'sum',
        'fecha': 'count'
    }).reset_index()
    df_agregado.columns = ['producto', 'segmento', 'qty_total', 'venta_total', 'frecuencia']
    
    # Aplicar log
    df_agregado['qty_log'] = np.log1p(df_agregado['qty_total'])
    df_agregado['venta_log'] = np.log1p(df_agregado['venta_total'])
    df_agregado['freq_log'] = np.log1p(df_agregado['frecuencia'])
    
    # Scatter plot interactivo
    fig = px.scatter(
        df_agregado,
        x='venta_log',
        y='freq_log',
        color='segmento',
        size='qty_log',
        hover_data=['producto', 'qty_total', 'venta_total', 'frecuencia'],
        title="Segmentaci√≥n K-Means de Productos Clase A",
        labels={
            'venta_log': 'Venta Total (log)',
            'freq_log': 'Frecuencia de Ventas (log)',
            'segmento': 'Segmento'
        },
        color_discrete_sequence=px.colors.qualitative.Plotly
    )
    fig.update_traces(marker=dict(line=dict(width=1, color='DarkSlateGrey')))
    fig.update_layout(
        height=600,
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        font_color="#FFFFFF"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ==========================================================
    # ‚≠ê INICIO DE BLOQUE MODIFICADO (PASO 1: DESCRIPCI√ìN DEL GR√ÅFICO)
    # ==========================================================
    st.info("""
    **¬øC√≥mo leer este gr√°fico?**
    
    Este gr√°fico agrupa cada producto (cada burbuja) en un segmento de comportamiento (color).
    
    * **Posici√≥n (Eje Y ‚¨Ü):** Cuanto m√°s **alto**, m√°s *frecuentemente* se vende el producto (m√°s meses con ventas).
    * **Posici√≥n (Eje X ‚û°):** Cuanto m√°s a la **derecha**, m√°s *valor total (Bs.)* ha generado el producto.
    * **Tama√±o de la Burbuja (üîµ):** Cuanto m√°s **grande**, m√°s *unidades totales* se han vendido.
    
    **Ideal:** Los mejores productos est√°n en la esquina superior derecha (se venden a menudo y generan mucho valor).
    """)
    # ==========================================================
    # ‚≠ê FIN DE BLOQUE MODIFICADO
    # ==========================================================
    
    # Estad√≠sticas por segmento
    st.subheader("Estad√≠sticas por Segmento")
    
    # ==========================================================
    # ‚≠ê INICIO DE BLOQUE MODIFICADO (PASO 2: TABLA MEJORADA)
    # ==========================================================
    stats = df_agregado.groupby('segmento').agg({
        'producto': 'count',
        'qty_total': ['mean', 'sum'],
        'venta_total': ['mean', 'sum'],
        'frecuencia': 'mean' # 'frecuencia' es el conteo de meses
    }).round(2)
    stats.columns = ['_'.join(col) for col in stats.columns.values] # Aplanar multi-index
    
    # Renombrar columnas a nombres m√°s claros con unidades
    stats = stats.rename(columns={
        'producto_count': 'N¬∞ de Productos',
        'qty_total_mean': 'Cant. Promedio (u./mes)',
        'qty_total_sum': 'Cant. Total (u.)',
        'venta_total_mean': 'Venta Promedio (Bs./mes)',
        'venta_total_sum': 'Venta Total (Bs.)',
        'frecuencia_mean': 'Meses Prom. de Historial'
    })
    
    # Aplicar formato para mejor legibilidad
    st.dataframe(
        stats.style
        .set_properties(**{'color': '#FFFFFF'}) # Texto blanco
        .set_table_styles([{'selector': 'thead th', 'props': [('color', '#E0E0E0')]}])
        .format({
            'N¬∞ de Productos': '{:,.0f}',
            'Cant. Promedio (u./mes)': '{:,.2f} u.',
            'Cant. Total (u.)': '{:,.0f} u.',
            'Venta Promedio (Bs./mes)': 'Bs. {:,.2f}',
            'Venta Total (Bs.)': 'Bs. {:,.0f}',
            'Meses Prom. de Historial': '{:,.1f}'
        }),
        use_container_width=True
    )
    # ==========================================================
    # ‚≠ê FIN DE BLOQUE MODIFICADO
    # ==========================================================

# =============================================================================
# P√ÅGINA 5: SALUD DEL MODELO (Antes Tab 4)
# =============================================================================
elif pagina_seleccionada == "Salud del Modelo (MLOps)":

    st.header("Monitoreo de Salud del Modelo - Detecci√≥n de Drift")
    
    st.markdown("""
    Esta secci√≥n muestra el estado de **drift** (deriva) del modelo, 
    evaluando el rendimiento actual vs. baseline en datos recientes.
    """)
    
    # Configuraci√≥n de umbrales
    UMBRAL_CRITICO_F1_BINARIO = 0.85
    UMBRAL_CRITICO_AUC_RANGOS = 0.55
    UMBRAL_DRIFT_F1_BINARIO = 0.95
    UMBRAL_DRIFT_AUC_RANGOS = 0.90
    
    # Intentar cargar reporte de monitoreo existente
    reporte_path = os.path.join(DIR_REENTRENADOS, 'reporte_monitoreo.csv')
    alertas_path = os.path.join(DIR_REENTRENADOS, 'alertas_mlops.csv')
    
    try:
        df_reporte = pd.read_csv(reporte_path)
        
        # Resumen general
        col1, col2, col3 = st.columns(3)
        total_modelos = len(df_reporte)
        modelos_ok = (df_reporte['reentrenado'] == False).sum()
        modelos_reentrenados = df_reporte['reentrenado'].sum()
        
        col1.metric("Total de Modelos", total_modelos)
        col2.metric("üü¢ Modelos Estables", modelos_ok)
        col3.metric("üî¥ Modelos Re-entrenados", int(modelos_reentrenados))
        
        st.markdown("---")
        
        # An√°lisis detallado por segmento
        for idx, row in df_reporte.iterrows():
            segmento = row['segmento']
            f1_baseline = row['f1_baseline']
            f1_actual = row['f1_actual']
            auc_baseline = row['auc_baseline']
            auc_actual = row['auc_actual']
            reentrenado = row['reentrenado']
            
            # MODIFICADO: Emoji eliminado
            with st.expander(f"Segmento: {segmento}", expanded=(reentrenado == True)):
                # Determinar estado del modelo
                alertas = []
                
                # Chequeos cr√≠ticos
                if pd.notna(f1_actual) and f1_actual < UMBRAL_CRITICO_F1_BINARIO:
                    alertas.append(('CRITICAL', f'F1 Binario cr√≠ticamente bajo: {f1_actual:.3f} < {UMBRAL_CRITICO_F1_BINARIO}'))
                
                if pd.notna(auc_actual) and auc_actual < UMBRAL_CRITICO_AUC_RANGOS:
                    alertas.append(('CRITICAL', f'AUC Rangos cr√≠ticamente bajo: {auc_actual:.3f} < {UMBRAL_CRITICO_AUC_RANGOS}'))
                
                # Chequeos de drift
                if pd.notna(f1_actual) and pd.notna(f1_baseline) and f1_actual < f1_baseline * UMBRAL_DRIFT_F1_BINARIO:
                    alertas.append(('WARNING', f'Drift en F1 Binario: {f1_actual:.3f} < {f1_baseline * UMBRAL_DRIFT_F1_BINARIO:.3f}'))
                
                if pd.notna(auc_actual) and pd.notna(auc_baseline) and auc_actual < auc_baseline * UMBRAL_DRIFT_AUC_RANGOS:
                    alertas.append(('WARNING', f'Drift en AUC Rangos: {auc_actual:.3f} < {auc_baseline * UMBRAL_DRIFT_AUC_RANGOS:.3f}'))
                
                # Determinar estado general
                if reentrenado:
                    estado = "üî¥ MODELO RE-ENTRENADO"
                    color = "red"
                    mensaje = "El modelo fue re-entrenado debido a degradaci√≥n cr√≠tica del rendimiento."
                elif any(a[0] == 'CRITICAL' for a in alertas):
                    estado = "üî¥ CR√çTICO"
                    color = "red"
                    mensaje = "Rendimiento cr√≠tico detectado. Re-entrenamiento necesario."
                elif any(a[0] == 'WARNING' for a in alertas):
                    estado = "üü° ADVERTENCIA"
                    color = "orange"
                    mensaje = "Se detect√≥ drift moderado. Monitoreo recomendado."
                else:
                    estado = "üü¢ OK"
                    color = "green"
                    mensaje = "El modelo est√° estable y funcionando correctamente."
                
                # Mostrar estado
                col1, col2 = st.columns([1, 3])
                with col1:
                    st.markdown(f"### {estado}")
                with col2:
                    # Calcular score de salud (0-1)
                    if pd.notna(f1_actual):
                        health_score = min(f1_actual / f1_baseline if f1_baseline > 0 else 1.0, 1.0)
                    else:
                        health_score = 0.5 # Default si no hay datos
                    st.progress(health_score)
                    st.caption(f"Score de Salud: {health_score:.1%}")
                
                st.markdown(f":{color}[{mensaje}]")
                
                # Mostrar alertas espec√≠ficas
                if alertas:
                    # MODIFICADO: Emoji eliminado
                    st.markdown("**Alertas detectadas:**")
                    for tipo, msg in alertas:
                        if tipo == 'CRITICAL':
                            # MODIFICADO: Emoji eliminado
                            st.error(f"{msg}")
                        else:
                            # MODIFICADO: Emoji eliminado
                            st.warning(f"{msg}")
                
                # M√©tricas comparativas
                st.markdown("**üìä M√©tricas de Rendimiento:**")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric(
                        "Precisi√≥n Ocurrencia (F1)",
                        f"{f1_actual:.3f}" if pd.notna(f1_actual) else "N/A",
                        delta=f"{f1_actual - f1_baseline:.3f}" if pd.notna(f1_actual) and pd.notna(f1_baseline) else None
                    )
                
                with col2:
                    st.metric(
                        "F1 Baseline",
                        f"{f1_baseline:.3f}" if pd.notna(f1_baseline) else "N/A"
                    )
                
                with col3:
                    st.metric(
                        "Precisi√≥n Volumen (AUC)",
                        f"{auc_actual:.3f}" if pd.notna(auc_actual) else "N/A",
                        delta=f"{auc_actual - auc_baseline:.3f}" if pd.notna(auc_actual) and pd.notna(auc_baseline) else None
                    )
                
                with col4:
                    st.metric(
                        "AUC Baseline",
                        f"{auc_baseline:.3f}" if pd.notna(auc_baseline) else "N/A"
                    )
                
                # Gr√°fico de evoluci√≥n
                if pd.notna(f1_actual) and pd.notna(auc_actual) and pd.notna(f1_baseline) and pd.notna(auc_baseline):
                    fig_data = {
                        'M√©trica': ['Precisi√≥n Ocurrencia (F1)', 'Precisi√≥n Volumen (AUC)'],
                        'Baseline': [f1_baseline, auc_baseline],
                        'Actual': [f1_actual, auc_actual]
                    }
                    df_fig = pd.DataFrame(fig_data).melt('M√©trica', var_name='Tipo', value_name='Score')
                    
                    fig = px.bar(
                        df_fig,
                        x='M√©trica',
                        y='Score',
                        color='Tipo',
                        barmode='group',
                        text_auto='.3f',
                        title="Comparaci√≥n Baseline vs. Actual"
                    )
                    fig.update_layout(
                        height=350, 
                        yaxis=dict(range=[0,1]),
                        paper_bgcolor='rgba(0,0,0,0)',
                        plot_bgcolor='rgba(0,0,0,0)',
                        font_color="#FFFFFF",
                        legend_title_font_color="#FFFFFF",
                        legend_font_color="#FFFFFF"
                    )
                    st.plotly_chart(fig, use_container_width=True)
        
        # Mostrar alertas si existen
        if os.path.exists(alertas_path):
            st.markdown("---")
            # MODIFICADO: Emoji eliminado
            st.subheader("Historial de Alertas")
            df_alertas = pd.read_csv(alertas_path)
            st.dataframe(df_alertas.style.set_properties(**{'color': '#FFFFFF'}), use_container_width=True, height=300) # Texto blanco
    
    except FileNotFoundError:
        # MODIFICADO: Emoji eliminado
        st.warning(f"""
        **No se encontr√≥ el reporte de monitoreo en `{reporte_path}`.**
        
        Para generar el reporte de salud del modelo, ejecuta la **Celda 11** del notebook:
        - Sistema de Re-entrenamiento y Alertas (MLOps)
        
        Esto crear√° el archivo `reporte_monitoreo.csv` necesario para esta pesta√±a.
        """)
        
        
        st.info("""
        **¬øQu√© hace la Celda 11?**
        1. Eval√∫a el rendimiento actual del modelo vs. baseline
        2. Detecta drift (degradaci√≥n del modelo)
        3. Re-entrena autom√°ticamente si es necesario
        4. Genera alertas y reportes de monitoreo
        """)